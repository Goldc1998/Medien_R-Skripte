# Benötigte Pakete installieren und laden
packages <- c("dplyr", "readr", "tidytext", "stringr", "stopwords", "SnowballC", "ggplot2")
new.packages <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new.packages)) install.packages(new.packages)
lapply(packages, library, character.only = TRUE)

# Daten laden
text_data <- read_csv("Medien_Gesamt_bereinigt.csv")

# Stoppwörter definieren
custom_stop_words <- c(stopwords::stopwords("de"), "sind", "wird", "dass", "diese", "einem")

# Tokenisierung, Stemming und Zählen der häufigsten Wörter
word_counts <- text_data %>%
  unnest_tokens(word, cleaned_hits) %>%               # Tokenisierung in einzelne Wörter
  filter(!word %in% custom_stop_words) %>%            # Entfernen der Stoppwörter
  mutate(word = wordStem(word, language = "de")) %>%  # Stemming anwenden
  count(word, sort = TRUE) %>%                        # Zählen der Wortfrequenzen
  slice_max(n, n = 50)                                # Top 50 häufigste Wörter mit slice_max()

# Aufteilen in die ersten beiden und die Wörter 3-40
first_2 <- word_counts[1:2, ]
rest_3_40 <- word_counts[3:40, ]

# Speichern der Tabellen als CSV-Dateien
write_csv(first_2, "First_2_Haeufigste_Woerter.csv")
write_csv(rest_3_40, "Rest_3_40_Haeufigste_Woerter.csv")
write_csv(word_counts, "Top_50_Haeufigste_Woerter.csv")  # Gesamt-CSV mit allen 50 Wörtern

# Visualisierung der ersten beiden häufigsten Wörter
first_2_plot <- ggplot(first_2, aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "black", width = 0.3) +  
  coord_flip() +
  labs(title = "Die ersten 2 Häufigsten Wörter im Gesamtmedienkorpus", 
       x = "Wort", 
       y = "Häufigkeit des Vorkommens") +  
  theme_minimal() +
  scale_y_continuous(labels = scales::comma) +  
  theme(
    axis.title.x = element_text(size = 14),      
    axis.title.y = element_text(size = 14),      
    axis.text.x = element_text(size = 12),       
    axis.text.y = element_text(size = 12),       
    plot.title = element_text(size = 16, face = "bold")  
  )

# Speichern der Visualisierung der ersten beiden als PNG
ggsave("First_2_Haeufigste_Woerter.png", plot = first_2_plot, width = 10, height = 8)

# Visualisierung der Wörter 3-40
rest_3_40_plot <- ggplot(rest_3_40, aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "steelblue", width = 0.3) +  
  coord_flip() +
  labs(title = "Wörter 3-40 Häufigste Wörter im Gesamtmedienkorpus", 
       x = "Wort", 
       y = "Häufigkeit des Vorkommens") +  
  theme_minimal() +
  scale_y_continuous(labels = scales::comma) +  
  theme(
    axis.title.x = element_text(size = 14),      
    axis.title.y = element_text(size = 14),      
    axis.text.x = element_text(size = 12),       
    axis.text.y = element_text(size = 12),       
    plot.title = element_text(size = 12, face = "bold")  
  )

# Speichern der Visualisierung der Wörter 3-40 als PNG
ggsave("Rest_3_40_Haeufigste_Woerter.png", plot = rest_3_40_plot, width = 10, height = 8)

# Ausgabe der ersten 6 Zeilen der Ergebnis-Tabelle
print(head(word_counts))

