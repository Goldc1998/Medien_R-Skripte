# Sicherstellen, dass alle benötigten Pakete installiert sind
if (!require(tm)) install.packages("tm")
if (!require(slam)) install.packages("slam")
if (!require(widyr)) install.packages("widyr")
if (!require(ggraph)) install.packages("ggraph")
if (!require(igraph)) install.packages("igraph")
if (!require(dplyr)) install.packages("dplyr")
if (!require(tidytext)) install.packages("tidytext")
if (!require(stringr)) install.packages("stringr")
if (!require(SnowballC)) install.packages("SnowballC")

library(tm)
library(slam)
library(widyr)
library(ggraph)
library(igraph)
library(dplyr)
library(tidytext)
library(stringr)
library(SnowballC)

# Den Korpus laden 
data <- read.csv("Medien_Gesamt_bereinigt.csv", stringsAsFactors = FALSE)

# Überprüfen, ob die Spalte "cleaned_hits" vorhanden ist
if (!"cleaned_hits" %in% colnames(data)) {
  stop("Die Spalte 'cleaned_hits' ist nicht im Datensatz enthalten!")
}

# Nur die Spalte "cleaned_hits" verwenden
cleaned_hits <- data$cleaned_hits

# Tokenisieren der "cleaned_hits"-Spalte in einzelne Wörter
hits_words <- tibble(id = 1:length(cleaned_hits), text = cleaned_hits) %>%
  unnest_tokens(word, text)  # Tokenisieren in einzelne Wörter

# Anwenden des Stemmings auf die Tokens
hits_words <- hits_words %>%
  mutate(word = wordStem(word, language = "german"))

# Entferne Stopwörter
hits_words_clean <- hits_words %>%
  filter(!word %in% custom_stopwords)

# Wortpaare aus der "cleaned_hits"-Spalte berechnen
word_pairs <- hits_words_clean %>% 
  pairwise_count(word, id, sort = TRUE, upper = FALSE)  # Wortpaare berechnen

# Wortpaare mit einer Mindestanzahl von 2700 (z.B. nur häufige Paare)
word_pairs_filtered <- word_pairs %>% 
  filter(n >= 2700)  # Filtert nur Paare mit mindestens 2700 Vorkommen

# Exportiere die gefilterten Wortpaare als CSV (sortiert nach Häufigkeit absteigend)
write.csv(word_pairs_filtered, "word_pairs_min2700.csv", row.names = FALSE)
cat("Die CSV-Datei 'word_pairs_min2700.csv' wurde erstellt.\n")

# Visualisierung der Wortpaare aus "cleaned_hits" als Netzwerk
set.seed(1234)
graph_obj <- word_pairs_filtered %>% 
  graph_from_data_frame()

plot <- ggraph(graph_obj, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "steelblue") +
  geom_node_point(size = 3) +  # Kleinere Knotenpunkte (von 5 auf 3 reduziert)
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines"),
                 max.overlaps = 500,  # Erhöhte max.overlaps auf 500
                 size = 3) +  # Kleinere Schriftgröße für die Labels
  theme_void() +
  ggtitle("Wortpaare aus der 'cleaned_hits'-Spalte (min. 2700 Vorkommen)") +
  theme(legend.position = "none")  # Entfernen der Legende

# Speichern der Visualisierung
ggsave("word_pairs_network_min2700.png", plot = plot, width = 10, height = 6)
cat("Die Visualisierung wurde als 'word_pairs_network_min2700.png' gespeichert.\n")

# Benötigte Pakete laden
if (!require(dplyr)) install.packages("dplyr")
if (!require(gridExtra)) install.packages("gridExtra")
library(dplyr)
library(gridExtra)

# CSV-Datei einlesen (passen Sie den Dateinamen/Pfad an)
pairs <- read.csv("word_pairs_min2700.csv", stringsAsFactors = FALSE)

# Sortieren nach Häufigkeit absteigend
sorted_pairs <- pairs %>% 
  arrange(desc(n))

# Erste Tabelle: Zeilen 1 bis 25
top_25 <- sorted_pairs[1:25, ]

# Zweite Tabelle: Zeilen 26 bis 50
next_25 <- sorted_pairs[26:50, ]

# Speichern der beiden Tabellen als CSV-Dateien
write.csv(top_25, "word_pairs_1_25.csv", row.names = FALSE)
write.csv(next_25, "word_pairs_26_50.csv", row.names = FALSE)

# Speichern der beiden Tabellen als PNG-Dateien mit Überschriften
# Tabelle 1-25 mit Überschrift "Anzahl häufigster Wortpaare (1-25)"
png("word_pairs_1_25.png", width = 800, height = 600)
grid.arrange(tableGrob(top_25), top = "Anzahl häufigster Wortpaare (1-25)")
dev.off()

# Tabelle 26-50 mit Überschrift "Anzahl häufigster Wortpaare (26-50)"
png("word_pairs_26_50.png", width = 800, height = 600)
grid.arrange(tableGrob(next_25), top = "Anzahl häufigster Wortpaare (26-50)")
dev.off()

cat("Die CSV-Dateien 'word_pairs_1_25.csv' und 'word_pairs_26_50.csv' sowie die PNG-Dateien 'word_pairs_1_25.png' und 'word_pairs_26_50.png' wurden erstellt.\n")

